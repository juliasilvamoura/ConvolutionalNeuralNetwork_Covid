{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htip3OcADyz"
      },
      "source": [
        "# 1 - Conectar com o Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvmAiawG-e53",
        "outputId": "d0dd4cb7-bdbb-4eac-eb49-0f20d710c13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conectar com o drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyB3-jsEA9hr"
      },
      "source": [
        "# 2 - Importando bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XbgzD38cBAoZ"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas utilizadas para o desenvolvimento\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, BatchNormalization, Dropout, AveragePooling2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7HqgdQm_2hL"
      },
      "source": [
        "# 3 - Importar Dataset COVIDGR 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DNxMfFsEAMWy"
      },
      "outputs": [],
      "source": [
        "# Path dataset e saída\n",
        "\n",
        "input_database = '/content/drive/My Drive/cnn/dataset'\n",
        "\n",
        "# Escolha o modelo de CNN\n",
        "# 1 - LeNet\n",
        "# 2 - AlexNet\n",
        "# 3 - VGG\n",
        "\n",
        "modelo = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnUB4z7S4E4"
      },
      "source": [
        "# 4 - Criar e Treinar a rede convolucional\n",
        "\n",
        "###Conv2D\n",
        "\n",
        "\n",
        "*   **filters** - obrigatório, filtros de determina o número de filtros de saída das camadas convolucionais que aprenderão.\n",
        "\n",
        "*   **kernel_size** - dimensão do Kernel (matriz de convolução) (tuplas de valor inteiro ímpar).\n",
        "\n",
        "*   **padding** - \"valid\" (não adiciona zeros e reduz espaços sem valor) ou \"same\" (mantem o tamanho original).\n",
        "\n",
        "*   **strides** - tamanho das passadas.\n",
        "\n",
        "*   **activation** - parâmetro de conveniência que permite fornecer uma string.\n",
        "\n",
        "*   **input_shape** - imagem de entrada\n",
        "\n",
        "\n",
        "###MaxPooling2D\n",
        "\n",
        "\n",
        "*   **pool_size** - Tamanho do filtro, primeiro parâmetro\n",
        "\n",
        "*   **strides** - tamanho da passada, segundo parâmetro\n",
        "\n",
        "\n",
        "###Dense\n",
        "\n",
        "\n",
        "*   **units** - inteiro, dimensão do espaço de saída\n",
        "\n",
        "*   **activation** - \"relu\" o máximo de elemento de 0 e o tensor de entrada\n",
        "\n",
        "*   **activation** - \"softmax\" um vetor de valores de entrada e realiza a previsão da probabilistica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hHIHp26ge11p"
      },
      "outputs": [],
      "source": [
        "def model_CNN(modelo):\n",
        "  if(modelo == 1):\n",
        "\n",
        "    # Rede convolucional LeNet\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        # Camada de entrada/Convolucional\n",
        "        keras.layers.Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='tanh', padding=\"same\", input_shape=(28,28,1)),\n",
        "        #Camada Polling - média\n",
        "        keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "        keras.layers.Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh', padding=\"valid\"),\n",
        "        keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "        keras.layers.Conv2D(filters=120, kernel_size=(5,5), strides=(1,1), activation='tanh', padding=\"valid\"),\n",
        "        # Camada Densamente Conectada\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(84, activation='tanh'),\n",
        "        # Função Softmax\n",
        "        keras.layers.Dense(2, activation='softmax') \n",
        "    ])\n",
        "  elif(modelo == 2):\n",
        "\n",
        "    # Rede Convolucional AlexNet\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        \n",
        "        # Camada de entrada/Convolucional\n",
        "        keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', padding=\"same\", input_shape=(227,227,1)),\n",
        "        # Normalização\n",
        "        keras.layers.BatchNormalization(),\n",
        "        # Camanda Polling - valor máximo \n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "\n",
        "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        # Camada Densamente Conectada\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        #Função Softmax\n",
        "        keras.layers.Dense(2, activation='softmax') \n",
        "    ])\n",
        "  elif(modelo ==3):\n",
        "\n",
        "    # Rede Convolucional VGG16\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        # Bloco 1\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",input_shape=(224,224,1)),\n",
        "        keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 2\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 3\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 4\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 5\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Camada Densamente conectada\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(4096,activation=\"relu\"),\n",
        "        keras.layers.Dense(4096,activation=\"relu\"),\n",
        "        # Função Softmax\n",
        "        keras.layers.Dense(2, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_focal_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWE9hWs1J4vU"
      },
      "source": [
        "# 5 - Normalizando as imagens e separando para test e train\n",
        "\n",
        "Para isso usaremos o **ImageDataGenerator** e o **flow_from_directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUgXJbSLKLPL",
        "outputId": "8afe7167-e2cd-49ba-ef10-c011df149d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 254 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "if(modelo == 1):\n",
        "  target_size = (28,28)\n",
        "  name_model = \"LeNet\"\n",
        "elif(modelo == 2):\n",
        "  target_size = (227,227)\n",
        "  name_model = \"AlexNet\"\n",
        "elif(modelo == 3):\n",
        "  target_size = (224,224)\n",
        "  name_model = \"VGG\"\n",
        "\n",
        "model = model_CNN(modelo)\n",
        "\n",
        "# Normalizar as imagens e dividindo 30% para teste e 70% para traino\n",
        "datagen = ImageDataGenerator(rescale=1.0 / 255.0,\n",
        "                                  validation_split=0.30)\n",
        "\n",
        "# Criando Test e train\n",
        "data_train = datagen.flow_from_directory(input_database,\n",
        "                                        color_mode = \"grayscale\",\n",
        "                                        batch_size = 32,\n",
        "                                        target_size = target_size,\n",
        "                                        subset=\"training\"\n",
        "                                        )\n",
        "\n",
        "data_test = datagen.flow_from_directory(input_database,\n",
        "                                      color_mode = \"grayscale\",\n",
        "                                      batch_size = 32,\n",
        "                                      target_size = target_size,\n",
        "                                      subset='validation'\n",
        "                                      )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI5zMO-9tgz4"
      },
      "source": [
        "# 6 - Treinar e Fitting para o modelo\n",
        "\n",
        "### Compile\n",
        "\n",
        "*   Optimizer - Otimizador (Adam)\n",
        "\n",
        "*   Loss - Função de perda - calc. erro da precisão e valor real (binary_focal_crossentropy)\n",
        "\n",
        "*   Metrics - accuracy (precisão)\n",
        "\n",
        "### Fit\n",
        "\n",
        "*   data_train (dados de treino)\n",
        "\n",
        "*   epochs - quantidade de iterações com os dados oferecidos\n",
        "\n",
        "*   verbose - Modo de verbosidade (1 - barra de progresso/Padrão)\n",
        "\n",
        "*   steps_per_epoch - Nº Total de amostras\n",
        "\n",
        "*   Validation_steps - tamanho dos dados conhecidos da amostra do treinamento\n",
        "\n",
        "*  Validation_data -  Dados que sofreram avaliação da perda\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyUUmfUwfgNi",
        "outputId": "8c080002-2c1f-427e-caa3-1f503a95f09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 244s 13s/step - loss: 0.1743 - accuracy: 0.5334 - val_loss: 0.1653 - val_accuracy: 0.6260\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 86s 5s/step - loss: 0.1609 - accuracy: 0.6405 - val_loss: 0.1679 - val_accuracy: 0.6024\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1580 - accuracy: 0.6488 - val_loss: 0.1630 - val_accuracy: 0.6142\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1563 - accuracy: 0.6472 - val_loss: 0.1636 - val_accuracy: 0.6339\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 86s 5s/step - loss: 0.1540 - accuracy: 0.6656 - val_loss: 0.1605 - val_accuracy: 0.6181\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1516 - accuracy: 0.6839 - val_loss: 0.1587 - val_accuracy: 0.6378\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1535 - accuracy: 0.6789 - val_loss: 0.1602 - val_accuracy: 0.6142\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1549 - accuracy: 0.6756 - val_loss: 0.1598 - val_accuracy: 0.6299\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1508 - accuracy: 0.6806 - val_loss: 0.1550 - val_accuracy: 0.6417\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1501 - accuracy: 0.6605 - val_loss: 0.1570 - val_accuracy: 0.6299\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1476 - accuracy: 0.6823 - val_loss: 0.1545 - val_accuracy: 0.6496\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 88s 5s/step - loss: 0.1474 - accuracy: 0.6906 - val_loss: 0.1546 - val_accuracy: 0.6496\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1475 - accuracy: 0.6906 - val_loss: 0.1518 - val_accuracy: 0.6496\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1445 - accuracy: 0.7023 - val_loss: 0.1554 - val_accuracy: 0.6535\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1440 - accuracy: 0.7057 - val_loss: 0.1553 - val_accuracy: 0.6575\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1413 - accuracy: 0.7140 - val_loss: 0.1564 - val_accuracy: 0.6457\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 86s 5s/step - loss: 0.1437 - accuracy: 0.7090 - val_loss: 0.1576 - val_accuracy: 0.6220\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 88s 5s/step - loss: 0.1438 - accuracy: 0.7040 - val_loss: 0.1569 - val_accuracy: 0.6693\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1443 - accuracy: 0.7007 - val_loss: 0.1520 - val_accuracy: 0.6772\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 86s 5s/step - loss: 0.1410 - accuracy: 0.6957 - val_loss: 0.1585 - val_accuracy: 0.6417\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f538a60e730>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Training the model\n",
        "model.fit(data_train, steps_per_epoch=len(data_train), validation_data=data_test,validation_steps=len(data_test), epochs=20, verbose= 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHEAs1JhxyBf"
      },
      "source": [
        "# 7 - Previsão\n",
        "\n",
        "### Utilizando o evaluate para realizar a precisão\n",
        "\n",
        "Primeiro valor está relacionado ao erro ao realizar a comparação\n",
        "Segundo valor está relacionado a accuracy, ou seja, a precisão de acerto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NF5EByyCx0Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725c202d-177e-452a-c229-c24927c968d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 26s 3s/step - loss: 0.1585 - accuracy: 0.6417\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1584942489862442, 0.6417322754859924]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.evaluate(data_test,steps=len(data_test), verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 - Confusion Matrix"
      ],
      "metadata": {
        "id": "RzKoneZsEBYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_model = model.predict(data_test, steps=(len(data_test)))\n",
        "y_true = data_test.classes\n",
        "y_pred = predict_model.argmax(axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_true))\n",
        "\n",
        "disp.plot(cmap=plt.cm.RdPu) #Color\n",
        "plt.title(\"Confusion Matrix - model \"+ name_model)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uYMrqHbetJdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "35d3089b-6335-459d-da14-6c4fa1e73203"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 26s 3s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}