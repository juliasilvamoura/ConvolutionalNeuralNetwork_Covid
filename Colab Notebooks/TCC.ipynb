{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2htip3OcADyz"
      },
      "source": [
        "# 1 - Conectar com o Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvmAiawG-e53",
        "outputId": "13737948-e7ea-48e3-f876-1da219a5f9e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conectar com o drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyB3-jsEA9hr"
      },
      "source": [
        "# 2 - Importando bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XbgzD38cBAoZ"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas utilizadas para o desenvolvimento\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, BatchNormalization, Dropout, AveragePooling2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7HqgdQm_2hL"
      },
      "source": [
        "# 3 - Importar Dataset COVIDGR 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DNxMfFsEAMWy"
      },
      "outputs": [],
      "source": [
        "# Path dataset e saída\n",
        "\n",
        "input_database = '/content/drive/My Drive/cnn/dataset'\n",
        "\n",
        "# Escolha o modelo de CNN\n",
        "# 1 - LeNet\n",
        "# 2 - AlexNet\n",
        "# 3 - VGG\n",
        "\n",
        "modelo = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnUB4z7S4E4"
      },
      "source": [
        "# 4 - Criar e Treinar a rede convolucional\n",
        "\n",
        "###Conv2D\n",
        "\n",
        "\n",
        "*   **filters** - obrigatório, filtros de determina o número de filtros de saída das camadas convolucionais que aprenderão.\n",
        "\n",
        "*   **kernel_size** - dimensão do Kernel (matriz de convolução) (tuplas de valor inteiro ímpar).\n",
        "\n",
        "*   **padding** - \"valid\" (não adiciona zeros e reduz espaços sem valor) ou \"same\" (mantem o tamanho original).\n",
        "\n",
        "*   **strides** - tamanho das passadas.\n",
        "\n",
        "*   **activation** - parâmetro de conveniência que permite fornecer uma string.\n",
        "\n",
        "*   **input_shape** - imagem de entrada\n",
        "\n",
        "\n",
        "###MaxPooling2D\n",
        "\n",
        "\n",
        "*   **pool_size** - Tamanho do filtro, primeiro parâmetro\n",
        "\n",
        "*   **strides** - tamanho da passada, segundo parâmetro\n",
        "\n",
        "\n",
        "###Dense\n",
        "\n",
        "\n",
        "*   **units** - inteiro, dimensão do espaço de saída\n",
        "\n",
        "*   **activation** - \"relu\" o máximo de elemento de 0 e o tensor de entrada\n",
        "\n",
        "*   **activation** - \"softmax\" um vetor de valores de entrada e realiza a previsão da probabilistica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hHIHp26ge11p"
      },
      "outputs": [],
      "source": [
        "def model_CNN(modelo):\n",
        "  if(modelo == 1):\n",
        "\n",
        "    # Rede convolucional LeNet\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        # Camada de entrada/Convolucional\n",
        "        keras.layers.Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='tanh', padding=\"same\", input_shape=(28,28,1)),\n",
        "        #Camada Polling - média\n",
        "        keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "        keras.layers.Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh', padding=\"valid\"),\n",
        "        keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "        keras.layers.Conv2D(filters=120, kernel_size=(5,5), strides=(1,1), activation='tanh', padding=\"valid\"),\n",
        "        # Camada Densamente Conectada\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(120, activation='tanh'),\n",
        "        keras.layers.Dense(84, activation='tanh'),\n",
        "        # Função Softmax\n",
        "        keras.layers.Dense(2, activation='softmax') \n",
        "    ])\n",
        "  elif(modelo == 2):\n",
        "\n",
        "    # Rede Convolucional AlexNet\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        \n",
        "        # Camada de entrada/Convolucional\n",
        "        keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', padding=\"same\", input_shape=(227,227,1)),\n",
        "        # Normalização\n",
        "        keras.layers.BatchNormalization(),\n",
        "        # Camanda Polling - valor máximo \n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "\n",
        "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        # Camada Densamente Conectada\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        #Função Softmax\n",
        "        keras.layers.Dense(2, activation='softmax') \n",
        "    ])\n",
        "  elif(modelo ==3):\n",
        "\n",
        "    # Rede Convolucional VGG16\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        # Bloco 1\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",input_shape=(224,224,1)),\n",
        "        keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 2\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 3\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 4\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Bloco 5\n",
        "\n",
        "        # Camandas Convolucionais\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        # Camanda Polling - valor máximo\n",
        "        keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "        # Camada Densamente conectada\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(4096,activation=\"relu\"),\n",
        "        keras.layers.Dense(4096,activation=\"relu\"),\n",
        "        # Função Softmax\n",
        "        keras.layers.Dense(2, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_focal_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWE9hWs1J4vU"
      },
      "source": [
        "# 5 - Normalizando as imagens e separando para test e train\n",
        "\n",
        "Para isso usaremos o **ImageDataGenerator** e o **flow_from_directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUgXJbSLKLPL",
        "outputId": "5ca34526-939b-4347-bd83-ed0b2352e9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 598 images belonging to 2 classes.\n",
            "Found 254 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "if(modelo == 1):\n",
        "  target_size = (28,28)\n",
        "  name_model = \"LeNet\"\n",
        "elif(modelo == 2):\n",
        "  target_size = (227,227)\n",
        "  name_model = \"AlexNet\"\n",
        "elif(modelo == 3):\n",
        "  target_size = (224,224)\n",
        "  name_model = \"VGG\"\n",
        "\n",
        "model = model_CNN(modelo)\n",
        "\n",
        "# Normalizar as imagens e dividindo 30% para teste e 70% para traino\n",
        "datagen = ImageDataGenerator(rescale=1.0 / 255.0,\n",
        "                                  validation_split=0.30)\n",
        "\n",
        "# Criando Test e train\n",
        "data_train = datagen.flow_from_directory(input_database,\n",
        "                                        color_mode = \"grayscale\",\n",
        "                                        batch_size = 32,\n",
        "                                        target_size = target_size,\n",
        "                                        subset=\"training\"\n",
        "                                        )\n",
        "\n",
        "data_test = datagen.flow_from_directory(input_database,\n",
        "                                      color_mode = \"grayscale\",\n",
        "                                      batch_size = 32,\n",
        "                                      target_size = target_size,\n",
        "                                      subset='validation'\n",
        "                                      )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI5zMO-9tgz4"
      },
      "source": [
        "# 6 - Treinar e Fitting para o modelo\n",
        "\n",
        "### Compile\n",
        "\n",
        "*   Optimizer - Otimizador (Adam)\n",
        "\n",
        "*   Loss - Função de perda - calc. erro da precisão e valor real (binary_focal_crossentropy)\n",
        "\n",
        "*   Metrics - accuracy (precisão)\n",
        "\n",
        "### Fit\n",
        "\n",
        "*   data_train (dados de treino)\n",
        "\n",
        "*   epochs - quantidade de iterações com os dados oferecidos\n",
        "\n",
        "*   verbose - Modo de verbosidade (1 - barra de progresso/Padrão)\n",
        "\n",
        "*   steps_per_epoch - Nº Total de amostras\n",
        "\n",
        "*   Validation_steps - tamanho dos dados conhecidos da amostra do treinamento\n",
        "\n",
        "*  Validation_data -  Dados que sofreram avaliação da perda\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyUUmfUwfgNi",
        "outputId": "467a24df-4f27-4176-ef49-da11485cd047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 223s 12s/step - loss: 0.1736 - accuracy: 0.5819 - val_loss: 0.1671 - val_accuracy: 0.6063\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 82s 4s/step - loss: 0.1625 - accuracy: 0.6204 - val_loss: 0.1678 - val_accuracy: 0.5906\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1559 - accuracy: 0.6421 - val_loss: 0.1754 - val_accuracy: 0.5984\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 82s 4s/step - loss: 0.1583 - accuracy: 0.6388 - val_loss: 0.1687 - val_accuracy: 0.6024\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 82s 4s/step - loss: 0.1551 - accuracy: 0.6689 - val_loss: 0.1657 - val_accuracy: 0.6181\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 83s 4s/step - loss: 0.1533 - accuracy: 0.6689 - val_loss: 0.1624 - val_accuracy: 0.6457\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 86s 5s/step - loss: 0.1528 - accuracy: 0.6672 - val_loss: 0.1627 - val_accuracy: 0.6063\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 82s 4s/step - loss: 0.1523 - accuracy: 0.6806 - val_loss: 0.1609 - val_accuracy: 0.6535\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 84s 4s/step - loss: 0.1490 - accuracy: 0.6856 - val_loss: 0.1625 - val_accuracy: 0.6299\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 82s 4s/step - loss: 0.1493 - accuracy: 0.6906 - val_loss: 0.1591 - val_accuracy: 0.6535\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 82s 4s/step - loss: 0.1485 - accuracy: 0.6890 - val_loss: 0.1589 - val_accuracy: 0.6299\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1473 - accuracy: 0.6856 - val_loss: 0.1572 - val_accuracy: 0.6496\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 84s 4s/step - loss: 0.1484 - accuracy: 0.6856 - val_loss: 0.1566 - val_accuracy: 0.6535\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1444 - accuracy: 0.6940 - val_loss: 0.1568 - val_accuracy: 0.6496\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 85s 5s/step - loss: 0.1446 - accuracy: 0.7157 - val_loss: 0.1580 - val_accuracy: 0.6378\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 84s 5s/step - loss: 0.1412 - accuracy: 0.7040 - val_loss: 0.1597 - val_accuracy: 0.6457\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 84s 4s/step - loss: 0.1443 - accuracy: 0.7023 - val_loss: 0.1618 - val_accuracy: 0.6260\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1449 - accuracy: 0.7074 - val_loss: 0.1543 - val_accuracy: 0.6614\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 84s 5s/step - loss: 0.1406 - accuracy: 0.7124 - val_loss: 0.1601 - val_accuracy: 0.6654\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 87s 5s/step - loss: 0.1373 - accuracy: 0.7207 - val_loss: 0.1563 - val_accuracy: 0.6693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f83f8d95400>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Training the model\n",
        "model.fit(data_train, steps_per_epoch=len(data_train), validation_data=data_test,validation_steps=len(data_test), epochs=20, verbose= 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHEAs1JhxyBf"
      },
      "source": [
        "# 7 - Previsão\n",
        "\n",
        "### Utilizando o evaluate para realizar a precisão\n",
        "\n",
        "Primeiro valor está relacionado ao erro ao realizar a comparação\n",
        "Segundo valor está relacionado a accuracy, ou seja, a precisão de acerto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NF5EByyCx0Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ed174b-35c1-4138-ce6b-976931b95e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 27s 3s/step - loss: 0.1563 - accuracy: 0.6693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15627247095108032, 0.6692913174629211]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.evaluate(data_test,steps=len(data_test), verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 - Confusion Matrix"
      ],
      "metadata": {
        "id": "RzKoneZsEBYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_model = model.predict(data_test, steps=(len(data_test)))\n",
        "y_true = data_test.classes\n",
        "y_pred = predict_model.argmax(axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_true))\n",
        "\n",
        "disp.plot(cmap=plt.cm.RdPu) #Color\n",
        "plt.title(\"Confusion Matrix - model \"+ name_model)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uYMrqHbetJdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "67864130-af01-4c1a-950a-070e204e1234"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 26s 3s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}